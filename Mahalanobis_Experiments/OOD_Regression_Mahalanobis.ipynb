{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T04:50:08.433085Z",
     "start_time": "2019-12-03T04:50:08.427791Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import lib_regression\n",
    "import argparse\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--net_type', default='resnet', help='resnet')\n",
    "args = parser.parse_known_args()[0]\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T04:50:18.527692Z",
     "start_time": "2019-12-03T04:50:13.809546Z"
    }
   },
   "outputs": [],
   "source": [
    "# initial setup\n",
    "dataset_list = ['cifar10', 'cifar100', 'svhn']\n",
    "score_list = ['Mahalanobis_0.0', 'Mahalanobis_0.01', 'Mahalanobis_0.005', 'Mahalanobis_0.002', 'Mahalanobis_0.0014', 'Mahalanobis_0.001', 'Mahalanobis_0.0005']\n",
    "#score_list = ['Mahalanobis_0.0', 'Mahalanobis_0.01', 'Mahalanobis_0.005', 'Mahalanobis_0.002', 'Mahalanobis_0.0014', 'Mahalanobis_0.001', 'Mahalanobis_0.0005']\n",
    "# train and measure the performance of Mahalanobis detector\n",
    "list_best_results, list_best_results_index = [], []\n",
    "for dataset in dataset_list:\n",
    "    print('In-distribution: ', dataset)\n",
    "    outf = './output/' + args.net_type + '_' + dataset + '/'\n",
    "    out_list = ['svhn', 'imagenet_resize', 'lsun_resize']\n",
    "    if dataset == 'svhn':\n",
    "        out_list = ['cifar10', 'imagenet_resize', 'lsun_resize']\n",
    "\n",
    "    list_best_results_out, list_best_results_index_out = [], []\n",
    "    for out in out_list:\n",
    "        print('Out-of-distribution: ', out)\n",
    "        best_tnr, best_result, best_index = 0, 0, 0\n",
    "        for score in score_list:\n",
    "            total_X, total_Y = lib_regression.load_characteristics(score, dataset, out, outf)\n",
    "            X_val, Y_val, X_test, Y_test = lib_regression.block_split(total_X, total_Y, out)\n",
    "            X_train = np.concatenate((X_val[:500], X_val[1000:1500]))\n",
    "            Y_train = np.concatenate((Y_val[:500], Y_val[1000:1500]))\n",
    "            X_val_for_test = np.concatenate((X_val[500:1000], X_val[1500:]))\n",
    "            Y_val_for_test = np.concatenate((Y_val[500:1000], Y_val[1500:]))\n",
    "            lr = LogisticRegressionCV(n_jobs=-1).fit(X_train, Y_train)\n",
    "            y_pred = lr.predict_proba(X_train)[:, 1]\n",
    "            #print('training mse: {:.4f}'.format(np.mean(y_pred - Y_train)))\n",
    "            y_pred = lr.predict_proba(X_val_for_test)[:, 1]\n",
    "            #print('test mse: {:.4f}'.format(np.mean(y_pred - Y_val_for_test)))\n",
    "            results = lib_regression.detection_performance(lr, X_val_for_test, Y_val_for_test, outf)\n",
    "            if best_tnr < results['TMP']['TNR']:\n",
    "                best_tnr = results['TMP']['TNR']\n",
    "                best_index = score\n",
    "                best_result = lib_regression.detection_performance(lr, X_test, Y_test, outf)\n",
    "        list_best_results_out.append(best_result)\n",
    "        list_best_results_index_out.append(best_index)\n",
    "    list_best_results.append(list_best_results_out)\n",
    "    list_best_results_index.append(list_best_results_index_out)\n",
    "\n",
    "# print the results\n",
    "count_in = 0\n",
    "mtypes = ['TNR', 'AUROC', 'DTACC', 'AUIN', 'AUOUT']\n",
    "\n",
    "for in_list in list_best_results:\n",
    "    print('in_distribution: ' + dataset_list[count_in] + '==========')\n",
    "    out_list = ['svhn', 'imagenet_resize', 'lsun_resize']\n",
    "    if dataset_list[count_in] == 'svhn':\n",
    "        out_list = ['cifar10', 'imagenet_resize', 'lsun_resize']\n",
    "    count_out = 0\n",
    "    for results in in_list:\n",
    "        print('out_distribution: '+ out_list[count_out])\n",
    "        for mtype in mtypes:\n",
    "            print(' {mtype:6s}'.format(mtype=mtype), end='')\n",
    "        print('\\n{val:6.2f}'.format(val=100.*results['TMP']['TNR']), end='')\n",
    "        print(' {val:6.2f}'.format(val=100.*results['TMP']['AUROC']), end='')\n",
    "        print(' {val:6.2f}'.format(val=100.*results['TMP']['DTACC']), end='')\n",
    "        print(' {val:6.2f}'.format(val=100.*results['TMP']['AUIN']), end='')\n",
    "        print(' {val:6.2f}\\n'.format(val=100.*results['TMP']['AUOUT']), end='')\n",
    "        print('Input noise: ' + list_best_results_index[count_in][count_out])\n",
    "        print('')\n",
    "        count_out += 1\n",
    "    count_in += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
