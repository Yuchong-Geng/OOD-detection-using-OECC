{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GWPfZ3_I9MV3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/yg534/OOD-detection-using-OECC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y93km0Vl8-XT"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CIFAR.models.wrn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f91033b785de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWideResNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_results\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_measures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_measures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_measures_with_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CIFAR.models.wrn'"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, argparse, time\n",
    "sys.path.append('..')\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from skimage.filters import gaussian as gblur\n",
    "from PIL import Image as PILImage\n",
    "import seaborn as sns\n",
    "\n",
    "from CIFAR.models.wrn import WideResNet\n",
    "from utils.validation_dataset import validation_split\n",
    "from utils.display_results import show_performance, get_measures, print_measures, print_measures_with_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynpAc6k28-XV"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        'dataset': 'cifar10', # Change to 'cifar100' to run experiments with the CIFAR 100 dataset! \n",
    "        'model': 'wrn',  ## WideResNet for the CIFAR experiments\n",
    "        'calibration': '',\n",
    "        'epochs': 15, # The number of epochs to fine-tune with OECC\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 128,\n",
    "        'oe_batch_size': 256,\n",
    "        'test_bs': 200,\n",
    "        'momentum': 0.9,\n",
    "        'decay': 0.0005, # Weight decay (L2 penalty)\n",
    "        'save': './results/OECC_tune',\n",
    "        'load': './results/baseline', # Load the WideResNet model after it has been trained for 100 epochs using only Cross-entropy loss !\n",
    "        'test': 'store_true',\n",
    "        'layers': 40,\n",
    "        'widen_factor': 2,\n",
    "        'droprate': 0.3,\n",
    "        'ngpu': 2,\n",
    "        'prefetch': 4,  \n",
    "        'lambda_1': 0.07, ## To make the known classes have prediction probabilities around A_{tr}\n",
    "        'lambda_2': 0.05  ## To push the outliers towards uniform\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22719,
     "status": "ok",
     "timestamp": 1618420067389,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "0LNYbP878-XW",
    "outputId": "30e62d5f-7cbf-4e88-8265-3b055c9c741e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "40000\n",
      "Files already downloaded and verified\n",
      "10000\n",
      "Using downloaded and verified file: /content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/'\n",
    "\n",
    "state = {k: v for k, v in args.items()}\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "train_transform = trn.Compose([trn.RandomHorizontalFlip(), trn.RandomCrop(32, padding=4),\n",
    "                               trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "def get_target_label_idx(labels, targets):\n",
    "    \"\"\"\n",
    "    Get the indices of labels that are included in targets.\n",
    "    :param labels: array of labels\n",
    "    :param targets: list/tuple of target labels\n",
    "    :return: list with indices of target labels\n",
    "    \"\"\"\n",
    "    return np.argwhere(np.isin(labels, targets)).flatten().tolist()\n",
    "\n",
    "\n",
    "# cifar 10 train\n",
    "cifar_10_train = dset.CIFAR10(root_dir, train=True, download=True, transform=train_transform)\n",
    "class_name = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_idx_list = np.arange(len(cifar_10_train))\n",
    "train_local_idx = get_target_label_idx(cifar_10_train.targets, [0, 1, 2, 5, 6, 7, 8, 9])\n",
    "print(len(train_local_idx))\n",
    "train_data_in = Subset(cifar_10_train, train_local_idx)\n",
    "\n",
    "# cifar 10 test\n",
    "cifar_10_test = dset.CIFAR10(root_dir, train=False, download=True, transform=test_transform)\n",
    "test_idx_list = np.arange(len(cifar_10_test))\n",
    "test_local_idx = get_target_label_idx(cifar_10_test.targets, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(len(test_local_idx))\n",
    "test_data = Subset(cifar_10_test, test_local_idx)\n",
    "num_classes = 10\n",
    "    \n",
    "    \n",
    "calib_indicator = ''\n",
    "if args['calibration']:\n",
    "    train_data_in, val_data = validation_split(train_data_in, val_share=0.1)\n",
    "    calib_indicator = '_calib'\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=args['batch_size'], shuffle=False,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "    \n",
    "    \n",
    "ood_data = dset.SVHN(root_dir, download=True, split='train', transform=trn.Compose(\n",
    "    [trn.ToTensor(), trn.ToPILImage(), trn.RandomCrop(32, padding=4),\n",
    "     trn.RandomHorizontalFlip(), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "\n",
    "\n",
    "# Data Loaders\n",
    "train_loader_in = torch.utils.data.DataLoader(\n",
    "    train_data_in,\n",
    "    batch_size=args['batch_size'], shuffle=True,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "\n",
    "train_loader_out = torch.utils.data.DataLoader(\n",
    "    ood_data,\n",
    "    batch_size=args['oe_batch_size'], shuffle=False,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args['batch_size'], shuffle=False,\n",
    "    num_workers=args['prefetch'], pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T20:46:00.069801Z",
     "start_time": "2019-12-13T20:45:55.743083Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7408,
     "status": "ok",
     "timestamp": 1618420112139,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "C5wlJ50t8-XW",
    "outputId": "c608f50f-9cbd-47af-c711-826e12008f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored! Epoch: 999\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "net = WideResNet(args['layers'], num_classes, args['widen_factor'], dropRate=args['droprate'])\n",
    "\n",
    "# Restore the baseline WideResNet model\n",
    "model_found = False\n",
    "if args['load'] != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        model_name = '/content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/baseline model/baseline_model.pt'\n",
    "        if os.path.isfile(model_name):\n",
    "            net.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            model_found = True\n",
    "            break\n",
    "    if not model_found:\n",
    "        assert False, \"Could not find model to restore\"\n",
    "\n",
    "device = torch.device('cuda:0')    \n",
    "net = net.cuda()\n",
    "torch.cuda.manual_seed(1)    \n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "    weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "# Learning Rate\n",
    "def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "            1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_annealing(\n",
    "        step,\n",
    "        args['epochs'] * len(train_loader_in),\n",
    "        1,  # since lr_lambda computes multiplicative factor\n",
    "        1e-6 / args['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-13T21:01:43.224180Z",
     "start_time": "2019-12-13T20:46:13.069282Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 740906,
     "status": "ok",
     "timestamp": 1618420857419,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "ZgtWI5jKpvPX",
    "outputId": "b70d6b65-9501-45f7-9527-e44bbc8fc7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Time    50 | Train Loss 0.4585 | Test Loss 2.695 | Test Error 24.31\n",
      "Epoch   2 | Time    49 | Train Loss 0.3976 | Test Loss 2.715 | Test Error 24.49\n",
      "Epoch   3 | Time    49 | Train Loss 0.4242 | Test Loss 2.891 | Test Error 23.87\n",
      "Epoch   4 | Time    50 | Train Loss 0.3476 | Test Loss 2.927 | Test Error 23.73\n",
      "Epoch   5 | Time    49 | Train Loss 0.3731 | Test Loss 2.898 | Test Error 23.72\n",
      "Epoch   6 | Time    48 | Train Loss 0.3795 | Test Loss 2.978 | Test Error 23.67\n",
      "Epoch   7 | Time    48 | Train Loss 0.2846 | Test Loss 2.890 | Test Error 23.52\n",
      "Epoch   8 | Time    49 | Train Loss 0.2576 | Test Loss 2.830 | Test Error 23.44\n",
      "Epoch   9 | Time    49 | Train Loss 0.3156 | Test Loss 2.947 | Test Error 23.45\n",
      "Epoch  10 | Time    49 | Train Loss 0.3108 | Test Loss 2.901 | Test Error 23.54\n",
      "Epoch  11 | Time    49 | Train Loss 0.2789 | Test Loss 2.920 | Test Error 23.46\n",
      "Epoch  12 | Time    48 | Train Loss 0.3346 | Test Loss 2.899 | Test Error 23.23\n",
      "Epoch  13 | Time    49 | Train Loss 0.2517 | Test Loss 2.932 | Test Error 23.23\n",
      "Epoch  14 | Time    49 | Train Loss 0.2531 | Test Loss 2.908 | Test Error 23.24\n",
      "Epoch  15 | Time    49 | Train Loss 0.2452 | Test Loss 2.885 | Test Error 23.25\n"
     ]
    }
   ],
   "source": [
    "# /////////////// Training ///////////////\n",
    "def train():\n",
    "    net.train()  # enter train mode\n",
    "    loss_avg = 0.0\n",
    "\n",
    "    # start at a random point of the outlier dataset; this induces more randomness without obliterating locality\n",
    "    train_loader_out.dataset.offset = np.random.randint(len(train_loader_out.dataset))\n",
    "    for in_set, out_set in zip(train_loader_in, train_loader_out):\n",
    "        data = torch.cat((in_set[0], out_set[0]), 0)\n",
    "        target = in_set[1]\n",
    "\n",
    "\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        # forward\n",
    "        x = net(data)\n",
    "\n",
    "        # backward\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = F.cross_entropy(x[:len(in_set[0])], target)\n",
    "        \n",
    "        ## OECC Loss Function\n",
    "        if args['dataset'] == 'cifar10':\n",
    "            A_tr = 0.9486 # Training accuracy of CIFAR-10 baseline model\n",
    "        elif args['dataset'] == 'cifar100':\n",
    "            A_tr = 0.7573 # Training accuracy of CIFAR-100 baseline model    \n",
    "        sm = torch.nn.Softmax(dim=1) # Create a Softmax \n",
    "        probabilities = sm(x) # Get the probabilites for both In and Outlier Images\n",
    "        max_probs, _ = torch.max(probabilities, dim=1) # Take the maximum probabilities produced by softmax\n",
    "        prob_diff_in = max_probs[:len(in_set[0])] - A_tr # Push towards the training accuracy of the baseline\n",
    "        loss += args['lambda_1'] * torch.sum(prob_diff_in**2) ## 1st Regularization term\n",
    "        prob_diff_out = probabilities[len(in_set[0]):][:] - (1/num_classes)\n",
    "        loss += args['lambda_2'] * torch.sum(torch.abs(prob_diff_out)) ## 2nd Regularization term\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "    \n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "# test function\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward\n",
    "            output = net(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            # test loss average\n",
    "            loss_avg += float(loss.data)            \n",
    "            \n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Make save directory\n",
    "if not os.path.exists(args['save']):\n",
    "    os.makedirs(args['save'])\n",
    "if not os.path.isdir(args['save']):\n",
    "    raise Exception('%s is not a dir' % args['save'])\n",
    "\n",
    "with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_OECC_tune_training_results.csv'), 'w') as f:\n",
    "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
    "\n",
    "print('Beginning Training\\n')\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(0, args['epochs']):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                            '_OECC_tune_epoch_' + str(epoch) + '.pt'))\n",
    "    # Let us not waste space and delete the previous model\n",
    "    prev_path = os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                             '_OECC_tune_epoch_' + str(epoch - 1) + '.pt')\n",
    "    if os.path.exists(prev_path): os.remove(prev_path)\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                      '_OECC_tune_training_results.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy'],\n",
    "        ))\n",
    "\n",
    "    # # print state with rounded decimals\n",
    "    # print({k: round(v, 4) if isinstance(v, float) else v for k, v in state.items()})\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmxP85nzWbVu",
    "outputId": "c03f477d-4edf-4a4f-fd9e-5c40ca670c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/train_256_places365standard.tar\n",
      "Extracting /content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/train_256_places365standard.tar to /content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/\n"
     ]
    }
   ],
   "source": [
    "ood_data = dset.Places365(root_dir, small=True, download=True, split='train-standard', transform=trn.Compose(\n",
    "    [trn.ToTensor(), trn.ToPILImage(), trn.RandomCrop(32, padding=4),\n",
    "     trn.RandomHorizontalFlip(), trn.ToTensor(), trn.Normalize(mean, std)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "executionInfo": {
     "elapsed": 1560,
     "status": "error",
     "timestamp": 1618421035593,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "YReZS5VCCzQ2",
    "outputId": "a741a011-5ff2-4032-c8fa-349f49a8b871"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e27c2f3f6599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbegin_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-e8a56e1da43a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# start at a random point of the outlier dataset; this induces more randomness without obliterating locality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loader_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0min_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/places365.py\", line 87, in __getitem__\n    image = self.loader(file)\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 215, in default_loader\n    return pil_loader(path)\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\", line 195, in pil_loader\n    with open(path, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/data_256_standard/p/pier/00001494.jpg'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Data Loaders\n",
    "\n",
    "\n",
    "train_loader_out = torch.utils.data.DataLoader(\n",
    "    ood_data,\n",
    "    batch_size=args['oe_batch_size'], shuffle=True,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(0, args['epochs']):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                            '_OECC_tune_epoch_' + str(epoch) + '.pt'))\n",
    "    # Let us not waste space and delete the previous model\n",
    "    prev_path = os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                             '_OECC_tune_epoch_' + str(epoch - 1) + '.pt')\n",
    "    if os.path.exists(prev_path): os.remove(prev_path)\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                      '_OECC_tune_training_results.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy'],\n",
    "        ))\n",
    "\n",
    "    # # print state with rounded decimals\n",
    "    # print({k: round(v, 4) if isinstance(v, float) else v for k, v in state.items()})\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7795,
     "status": "ok",
     "timestamp": 1618420912492,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "oEQALUpraYba",
    "outputId": "b6d88b11-6df0-4a0a-85bb-77732076fbb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate 23.25\n",
      "\n",
      "Using CIFAR-10 as typical data\n",
      "Using downloaded and verified file: /content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/test_32x32.mat\n",
      "10000\n",
      "\n",
      "\n",
      "CIFAR-100 Detection\n",
      "FPR95:\t\t\t46.06\n",
      "AUROC: \t\t\t84.83\n",
      "AUPR:  \t\t\t46.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Test Results\n",
      "FPR95:\t\t\t46.06\n",
      "AUROC: \t\t\t84.83\n",
      "AUPR:  \t\t\t46.25\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "\n",
    "# /////////////// Detection Prelims ///////////////\n",
    "\n",
    "ood_num_examples = len(test_data) // 5\n",
    "expected_ap = ood_num_examples / (ood_num_examples + len(test_data))\n",
    "\n",
    "concat = lambda x: np.concatenate(x, axis=0)\n",
    "to_np = lambda x: x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_ood_scores(loader, in_dist=False):\n",
    "    _score = []\n",
    "    out_conf_score = []\n",
    "    in_conf_score = []\n",
    "    _right_score = []\n",
    "    _wrong_score = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            if batch_idx >= ood_num_examples // args[\n",
    "                    'test_bs'] and in_dist is False:\n",
    "                break\n",
    "\n",
    "#             data = data.cuda(device)\n",
    "            data = data.cuda()\n",
    "\n",
    "            output = net(data)\n",
    "            smax = to_np(F.softmax(output, dim=1))\n",
    "\n",
    "            if True:\n",
    "                _score.append(\n",
    "                    to_np((output.mean(1) - torch.logsumexp(output, dim=1))))\n",
    "                out_conf_score.append(np.max(smax, axis=1))\n",
    "            else:\n",
    "                _score.append(-np.max(smax, axis=1))\n",
    "                out_conf_score.append(np.max(smax, axis=1))\n",
    "\n",
    "            if in_dist:\n",
    "                in_conf_score.append(np.max(smax, axis=1))\n",
    "                preds = np.argmax(smax, axis=1)\n",
    "                targets = target.numpy().squeeze()\n",
    "                right_indices = preds == targets\n",
    "                wrong_indices = np.invert(right_indices)\n",
    "\n",
    "                if False:\n",
    "                    _right_score.append(\n",
    "                        to_np((output.mean(1) -\n",
    "                               torch.logsumexp(output, dim=1)))[right_indices])\n",
    "                    _wrong_score.append(\n",
    "                        to_np((output.mean(1) -\n",
    "                               torch.logsumexp(output, dim=1)))[wrong_indices])\n",
    "                else:\n",
    "                    _right_score.append(-np.max(smax[right_indices], axis=1))\n",
    "                    _wrong_score.append(-np.max(smax[wrong_indices], axis=1))\n",
    "\n",
    "    if in_dist:\n",
    "        return concat(in_conf_score).copy(), concat(_score).copy(), concat(_right_score).copy(), concat(_wrong_score).copy()\n",
    "    else:\n",
    "        return concat(out_conf_score).copy(), concat(_score)[:ood_num_examples].copy()\n",
    "\n",
    "\n",
    "in_conf_score, in_score, right_score, wrong_score = get_ood_scores(test_loader, in_dist=True)\n",
    "\n",
    "num_right = len(right_score)\n",
    "num_wrong = len(wrong_score)\n",
    "print('Error Rate {:.2f}'.format(100 * num_wrong / (num_wrong + num_right)))\n",
    "# f.write('\\nError Rate {:.2f}'.format(100 * num_wrong /\n",
    "#                                      (num_wrong + num_right)))\n",
    "\n",
    "# /////////////// End Detection Prelims ///////////////\n",
    "\n",
    "print('\\nUsing CIFAR-10 as typical data') if num_classes == 10 else print(\n",
    "    '\\nUsing CIFAR-100 as typical data')\n",
    "# f.write('\\nUsing CIFAR-10 as typical data') if num_classes == 10 else f.write(\n",
    "#     '\\nUsing CIFAR-100 as typical data')\n",
    "\n",
    "# /////////////// Error Detection ///////////////\n",
    "\n",
    "# print('\\n\\nError Detection')\n",
    "# f.write('\\n\\nError Detection')\n",
    "# show_performance(wrong_score, right_score, f, method_name=args['method_name'])\n",
    "\n",
    "# /////////////// OOD Detection ///////////////\n",
    "auroc_list, aupr_list, fpr_list = [], [], []\n",
    "\n",
    "\n",
    "def get_and_print_results(ood_loader, num_to_avg=1):\n",
    "\n",
    "    aurocs, auprs, fprs = [], [], []\n",
    "    for _ in range(num_to_avg):\n",
    "        out_conf_score, out_score = get_ood_scores(ood_loader)\n",
    "        measures = get_measures(out_score, in_score)\n",
    "        aurocs.append(measures[0])\n",
    "        auprs.append(measures[1])\n",
    "        fprs.append(measures[2])\n",
    "\n",
    "    auroc = np.mean(aurocs)\n",
    "    aupr = np.mean(auprs)\n",
    "    fpr = np.mean(fprs)\n",
    "    auroc_list.append(auroc)\n",
    "    aupr_list.append(aupr)\n",
    "    fpr_list.append(fpr)\n",
    "\n",
    "    if num_to_avg >= 5:\n",
    "        print_measures_with_std(aurocs, auprs, fprs, f, 'cifar10_wrn_OECC_tune')\n",
    "    else:\n",
    "        print_measures(auroc, aupr, fpr, f, 'cifar10_wrn_OECC_tune')\n",
    "    return out_conf_score    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# /////////////// CIFAR Data ///////////////\n",
    "\n",
    "\n",
    "# ood_idx = get_target_label_idx(cifar_10_train.targets, [3, 4])\n",
    "# ood_data = Subset(cifar_10_train, ood_idx)\n",
    "\n",
    "ood_data = dset.SVHN(root_dir, download=True, split='test', transform=trn.Compose(\n",
    "    [trn.ToTensor(), trn.ToPILImage(), trn.RandomCrop(32, padding=4),\n",
    "     trn.RandomHorizontalFlip(), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "\n",
    "\n",
    "ood_idx_idx = get_target_label_idx(cifar_10_train.targets, [3, 4])\n",
    "print(len(ood_idx_idx))\n",
    "ood_data = Subset(cifar_10_train, ood_idx_idx)\n",
    "\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data,\n",
    "                                         batch_size=args['test_bs'],\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args['prefetch'],\n",
    "                                         pin_memory=True)\n",
    "\n",
    "print(\n",
    "    '\\n\\nCIFAR-100 Detection') if True else print(\n",
    "        '\\n\\nCIFAR-10 Detection')\n",
    "# f.write('\\n\\nCIFAR-100 Detection'\n",
    "#         ) if 'cifar10_' in args['method_name'] else f.write(\n",
    "#             '\\n\\nCIFAR-10 Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "out_conf_score, out_score = get_ood_scores(ood_loader, in_dist=False)\n",
    "# /////////////// Mean Results ///////////////\n",
    "\n",
    "print('\\n\\nMean Test Results')\n",
    "# f.write('\\n\\nMean Test Results')\n",
    "print_measures(np.mean(auroc_list),\n",
    "               np.mean(aupr_list),\n",
    "               np.mean(fpr_list),\n",
    "               f,\n",
    "               method_name='cifar10_wrn_OECC_tune')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1vXt5dlb6Sa"
   },
   "outputs": [],
   "source": [
    "path = F\"/content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/oecc model/oecc_model.pt\"\n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1618330875645,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "4E-DdLmBa5A1",
    "outputId": "0c08da48-bce1-4052-92be-2a40e397f535"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9658599 , 0.4878148 , 0.9999244 , ..., 0.9826847 , 0.99909973,\n",
       "       0.9121903 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_conf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1618420915821,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "zhq1bfcTkkRQ",
    "outputId": "527d3dba-0bbd-4542-9fb6-341ddd7a7738"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(out_conf_score, density=True)\n",
    "\n",
    "ax.set_title(r'Out of Distribution')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 5996,
     "status": "ok",
     "timestamp": 1618334662165,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "4yA37ejZNvhK",
    "outputId": "3a975585-defb-48de-c798-c8bd95479608"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(out_conf_score, density=True)\n",
    "\n",
    "ax.set_title(r'Out of Distribution')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1618330887343,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "QrJDTV0La6nC",
    "outputId": "75ca8b73-b663-4e76-c5a3-b033ea15c58d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(out_conf_score, density=True)\n",
    "\n",
    "ax.set_title(r'Out of Distribution')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1618001855847,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "QUu2_ngRbL0_",
    "outputId": "1737ff43-55c4-4ae4-fad3-60d547a2c4f1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPcElEQVR4nO3dfYxldX3H8fdHFlSEKrijwoqONkAgNq12WlGrtYIWAaFNtaBFxdBuYuJjbS22adEaG2yVqNE+rE9QRVCpqav4gFEJSoQwgFqWJ1EXWB7cAZWqaAH99o97Vmcvs3Pvzr0zd3/D+5VM9s49Z87vN7/MvvfMmTN3U1VIktrzgElPQJK0NAZckhplwCWpUQZckhplwCWpUQZckhplwLXLSvLgJJ9KcmeSjy/xGE9Pcu0Y5/TZJC/tHp+U5KtjPPafJTl/XMfT6mfANbIkm5McsQyHfj7wSODhVfWCBcZ9Y5J7kvyoe7suybuT7Ldtn6r6SlUdPGig7lgfHrRfVT23qs7c2U9kgfGmk1SSNfOOfVZVPWfUY+v+w4BrV/ZY4LqquneRfT5aVXsD+wJ/DDwKuGx+xMchPf590S7FL0iN1bbLCkneluQHSb6b5LmL7H9IkguS/DDJpiTHds+/CfgH4PgkP05y8mLjVtU9VbUJOB6YA17XHeeZSbbMG+9vktzcnbFfm+TwJEcCfztvrG90+16Q5C1JLgLuAh7fPffn238KeXd3meeaJIfP27DddyZ9Z/kXdn/+sBvzKf2XZJI8Ncml3bEvTfLUedsuSPLmJBd1n8v5SdYutkZafQy4lsOTgWuBtcA/A+9Pkv6dkuwOfAo4H3gE8ErgrCQHV9WpwD/RO8Peq6reP8zAVfVz4JPA0xcY72DgFcDvdGftfwhsrqrP9Y31m/M+7MXAemBv4IYdfK7f7j7XU4FPJNl3iKk+o/vzYd2YX+ub677AecC7gIcDpwPnJXn4vN1eBLyM3trtAfzVEONqFTHgWg43VNV7u5ieCexH71p2v8OAvYDTquruqvoS8GnghSOOfwu9Syr9fg48EDg0ye5Vtbmqvj3gWGdU1aaqureq7llg+1bgHd13AB+l9w/X0SPNvudo4FtV9aFu7LOBa4Dnzdvng1V1XVX9FPgY8FtjGFcNMeBaDrdte1BVd3UP91pgv/2Bm6rqF/OeuwFYN+L464Dv9z9ZVdcDrwHeCGxNck6S/Qcc66YB22+u7V8R7gZ6n9eo9ue+Z/z9a3PbvMd3sfAaaxUz4JqkW4AD+n44+Bjg5qUesDvW84CvLLS9qj5SVb9H7wekBbx126YdHHLQy3Wu67s89Bh6nxfAT4A952171E4c95ZujvONtDZafQy4JukSemeOr0+ye5Jn0ovvOTt7oCRrkhwCnE0vlKcvsM/BSZ6V5IHAz4CfAtvO/r8HTC/hTpNHAK/q5v8C4BDgM922rwMndNtm6N0Wuc1cN/bjd3DczwAHJXlR97kdDxxK7xKTBBhwTVBV3U0v2M8Fbgf+FXhJVV2zE4c5PsmPgTuBjcAdwG9X1S0L7PtA4LRurNvoxfcN3bZtvyh0R5LLd2L8S4ADu2O+BXh+Vd3Rbft74NeBHwBvAj6y7YO6S0tvAS7q7sA5bP5Bu2McQ+9umjuA1wPHVNXtOzE3rXLxP3SQpDZ5Bi5JjTLgktQoAy5JjTLgktSoNYN3GZ+1a9fW9PT0Sg4pSc277LLLbq+qqf7nVzTg09PTzM7OruSQktS8JAu9Do+XUCSpVQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUSv6m5iSNEnTp5w3kXE3nzaO/+f6vjwDl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGDQx4kg8k2ZrkynnP7ZvkC0m+1f25z/JOU5LUb5gz8DOAI/ueOwX4YlUdCHyxe1+StIIGBryqLgS+3/f0ccCZ3eMzgT8a87wkSQMs9Rr4I6vq1u7xbcAjxzQfSdKQRv4hZlUVUDvanmR9ktkks3Nzc6MOJ0nqLDXg30uyH0D359Yd7VhVG6pqpqpmpqamljicJKnfUgO+EXhp9/ilwCfHMx1J0rCGuY3wbOBrwMFJtiQ5GTgNeHaSbwFHdO9LklbQwNcDr6oX7mDT4WOeiyRpJ/ibmJLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUqJECnuS1STYluTLJ2UkeNK6JSZIWt+SAJ1kHvAqYqaonALsBJ4xrYpKkxY16CWUN8OAka4A9gVtGn5IkaRhLDnhV3Qy8DbgRuBW4s6rO798vyfoks0lm5+bmlj5TSdJ2RrmEsg9wHPA4YH/gIUlO7N+vqjZU1UxVzUxNTS19ppKk7YxyCeUI4LtVNVdV9wCfAJ46nmlJkgYZJeA3Aocl2TNJgMOBq8czLUnSIKNcA78EOBe4HPif7lgbxjQvSdIAa0b54Ko6FTh1THORJO0EfxNTkhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUSMFPMnDkpyb5JokVyd5yrgmJkla3JoRP/6dwOeq6vlJ9gD2HMOcJElDWHLAkzwUeAZwEkBV3Q3cPZ5pSZIGGeUSyuOAOeCDSa5I8r4kD+nfKcn6JLNJZufm5kYYTpI03ygBXwM8Cfi3qnoi8BPglP6dqmpDVc1U1czU1NQIw0mS5hsl4FuALVV1Sff+ufSCLklaAUsOeFXdBtyU5ODuqcOBq8YyK0nSQKPehfJK4KzuDpTvAC8bfUqSpGGMFPCq+jowM6a5SJJ2gr+JKUmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1KiRA55ktyRXJPn0OCYkSRrOOM7AXw1cPYbjSJJ2wkgBT/Jo4GjgfeOZjiRpWKOegb8DeD3wix3tkGR9ktkks3NzcyMOJ0naZskBT3IMsLWqLltsv6raUFUzVTUzNTW11OEkSX1GOQN/GnBsks3AOcCzknx4LLOSJA205IBX1Ruq6tFVNQ2cAHypqk4c28wkSYvyPnBJatSacRykqi4ALhjHsSRJw/EMXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVFLDniSA5J8OclVSTYlefU4JyZJWtyaET72XuB1VXV5kr2By5J8oaquGtPcJEmLWPIZeFXdWlWXd49/BFwNrBvXxCRJixvLNfAk08ATgUsW2LY+yWyS2bm5uXEMJ0liDAFPshfwX8Brqup/+7dX1YaqmqmqmampqVGHkyR1Rgp4kt3pxfusqvrEeKYkSRrGKHehBHg/cHVVnT6+KUmShjHKGfjTgBcDz0ry9e7tqDHNS5I0wJJvI6yqrwIZ41wkSTvB38SUpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElq1JpRPjjJkcA7gd2A91XVaWOZlaRVbfqU8yY9hVVhyQFPshvwHuDZwBbg0iQbq+qqcU1OWikGRS0a5Qz8d4Hrq+o7AEnOAY4DDLiWzJBKwxsl4OuAm+a9vwV4cv9OSdYD67t3f5zk2hHG3BWsBW6f9CR2Ea7F9lyP7bkenbx15LV47EJPjnQNfBhVtQHYsNzjrJQks1U1M+l57Apci+25HttzPX5ludZilLtQbgYOmPf+o7vnJEkrYJSAXwocmORxSfYATgA2jmdakqRBlnwJparuTfIK4PP0biP8QFVtGtvMdl2r5nLQGLgW23M9tud6/MqyrEWqajmOK0laZv4mpiQ1yoBLUqMM+AKSHJnk2iTXJzllge1/meSqJN9M8sUkC96juVoMWo95+/1Jkkqyqm8dG2Y9kvxp9zWyKclHVnqOK2mIvy+PSfLlJFd0f2eOmsQ8V0KSDyTZmuTKHWxPknd1a/XNJE8aacCq8m3eG70fyH4beDywB/AN4NC+ff4A2LN7/HLgo5Oe9yTXo9tvb+BC4GJgZtLznvDXx4HAFcA+3fuPmPS8J7weG4CXd48PBTZPet7LuB7PAJ4EXLmD7UcBnwUCHAZcMsp4noHf1y9fIqCq7ga2vUTAL1XVl6vqru7di+ndA79aDVyPzpuBtwI/W8nJTcAw6/EXwHuq6gcAVbV1hee4koZZjwJ+rXv8UOCWFZzfiqqqC4HvL7LLccB/Vs/FwMOS7LfU8Qz4fS30EgHrFtn/ZHr/oq5WA9ej+zbwgKq6P7yQyTBfHwcBByW5KMnF3at2rlbDrMcbgROTbAE+A7xyZaa2S9rZvixq2X+VfjVLciIwA/z+pOcyKUkeAJwOnDThqexK1tC7jPJMet+dXZjkN6rqhxOd1eS8EDijqt6e5CnAh5I8oap+MemJtc4z8Psa6iUCkhwB/B1wbFX93wrNbRIGrcfewBOAC5Jspnddb+Mq/kHmMF8fW4CNVXVPVX0XuI5e0FejYdbjZOBjAFX1NeBB9F7o6v5orC9BYsDva+BLBCR5IvAf9OK9mq9vwoD1qKo7q2ptVU1X1TS9nwkcW1Wzk5nushvmJST+m97ZN0nW0ruk8p2VnOQKGmY9bgQOB0hyCL2Az63oLHcdG4GXdHejHAbcWVW3LvVgXkLpUzt4iYAk/wjMVtVG4F+AvYCPJwG4saqOndikl9GQ63G/MeR6fB54TpKrgJ8Df11Vd0xu1stnyPV4HfDeJK+l9wPNk6q7JWO1SXI2vX+813bX/E8Fdgeoqn+n9zOAo4DrgbuAl4003ipdR0la9byEIkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmN+n9vhstAEarpVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(in_conf_score, density=True)\n",
    "\n",
    "ax.set_title(r'In of Distribution')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OECC_tune_cifar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
