{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1617943914104,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "0YT3sxLYUSjI"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/yg534/OOD-detection-using-OECC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4346,
     "status": "ok",
     "timestamp": 1617943919050,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "ONVykl6aUCb8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys, argparse, time\n",
    "sys.path.append('..')\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from skimage.filters import gaussian as gblur\n",
    "from PIL import Image as PILImage\n",
    "import seaborn as sns\n",
    "\n",
    "from CIFAR.models.wrn import WideResNet \n",
    "from utils.display_results import show_performance, get_measures, print_measures, print_measures_with_std\n",
    "import utils.svhn_loader as svhn\n",
    "import utils.lsun_loader as lsun_loader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:28:25.400259Z",
     "start_time": "2019-10-23T03:28:25.396089Z"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1617943924792,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "WWxU3iYD0X5O"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        'calibration': '',\n",
    "        'epochs': 100,\n",
    "        'dataset':'cifar10',\n",
    "        'learning_rate': 0.1,\n",
    "        'batch_size': 128,\n",
    "        'test_bs': 200,\n",
    "        'model':'wrn',\n",
    "        'momentum': 0.9,\n",
    "        'decay': 0.0005,\n",
    "        'save':'/home/yg534/OOD-detection-using-OECC/CIFAR/',\n",
    "        'load': '',\n",
    "        'test': 'store_true',\n",
    "        'layers':40,\n",
    "        'widen_factor':2,\n",
    "        'droprate':0.3,\n",
    "        'ngpu': 4,\n",
    "        'prefetch': 4,    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:28:28.181002Z",
     "start_time": "2019-10-23T03:28:26.424910Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16017,
     "status": "ok",
     "timestamp": 1617943942930,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "iVaB5bl_JVri",
    "outputId": "ecf4ef80-edab-4874-d82d-d6eb07ac54b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/yg534/OOD-detection-using-OECC/CIFAR/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34305f8331464049aa8dcd0d2a0cf66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/yg534/OOD-detection-using-OECC/CIFAR/cifar-10-python.tar.gz to /home/yg534/OOD-detection-using-OECC/CIFAR/\n",
      "40000\n",
      "Files already downloaded and verified\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "root='/home/yg534/OOD-detection-using-OECC/CIFAR/dataset'\n",
    "\n",
    "state = {k: v for k, v in args.items()}\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "train_transform = trn.Compose([trn.RandomHorizontalFlip(), trn.RandomCrop(32, padding=4),\n",
    "                               trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "def get_target_label_idx(labels, targets):\n",
    "    \"\"\"\n",
    "    Get the indices of labels that are included in targets.\n",
    "    :param labels: array of labels\n",
    "    :param targets: list/tuple of target labels\n",
    "    :return: list with indices of target labels\n",
    "    \"\"\"\n",
    "    return np.argwhere(np.isin(labels, targets)).flatten().tolist()\n",
    "\n",
    "\n",
    "# cifar 10 train\n",
    "cifar_10_train = dset.CIFAR10(root, train=True, download=True, transform=train_transform)\n",
    "class_name = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_idx_list = np.arange(len(cifar_10_train))\n",
    "train_local_idx = get_target_label_idx(cifar_10_train.targets, [0, 1, 2, 5, 6, 7, 8, 9])\n",
    "print(len(train_local_idx))\n",
    "train_data = Subset(cifar_10_train, train_local_idx)\n",
    "\n",
    "# cifar 10 test\n",
    "cifar_10_test = dset.CIFAR10(root, train=False, download=True, transform=test_transform)\n",
    "test_idx_list = np.arange(len(cifar_10_test))\n",
    "test_local_idx = get_target_label_idx(cifar_10_test.targets, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(len(test_local_idx))\n",
    "test_data = Subset(cifar_10_test, test_local_idx)\n",
    "num_classes = 10\n",
    "\n",
    "calib_indicator = ''\n",
    "if args['calibration']:\n",
    "    train_data, val_data = validation_split(train_data, val_share=0.1)\n",
    "    calib_indicator = '_calib'\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=args['batch_size'], shuffle=True,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=args['test_bs'], shuffle=False,\n",
    "    num_workers=args['prefetch'], pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:28:28.258452Z",
     "start_time": "2019-10-23T03:28:28.183854Z"
    },
    "executionInfo": {
     "elapsed": 6139,
     "status": "ok",
     "timestamp": 1617943953334,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "DNmuZ5A6UCcD"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "net = WideResNet(args['layers'], num_classes, args['widen_factor'], dropRate=args['droprate'])\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "# Restore model if desired\n",
    "if args['load'] != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        model_name = os.path.join( args['load'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_baseline_epoch_' + str(i) + '.pt')\n",
    "        if os.path.isfile(model_name):\n",
    "            net.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            start_epoch = i + 1\n",
    "            break\n",
    "    if start_epoch == 0:\n",
    "        assert False, \"could not resume\"\n",
    "\n",
    "net.cuda()\n",
    "torch.cuda.manual_seed(1)\n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "    weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "\n",
    "def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "            1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_annealing(\n",
    "        step,\n",
    "        args['epochs'] * len(train_loader),\n",
    "        1,  # since lr_lambda computes multiplicative factor\n",
    "        1e-6 / args['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T04:34:36.132388Z",
     "start_time": "2019-10-23T03:28:29.487850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1950194,
     "status": "ok",
     "timestamp": 1617945908499,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "eQYV7aTgyGUQ",
    "outputId": "132f8c9b-9ad1-4655-ed7b-457943e287bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yg534/.conda/envs/torch-gpu/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Time    18 | Train Loss 1.0392 | Test Loss 3.175 | Test Error 53.76\n",
      "Epoch   2 | Time    17 | Train Loss 0.6893 | Test Loss 3.275 | Test Error 46.21\n",
      "Epoch   3 | Time    17 | Train Loss 0.6582 | Test Loss 2.823 | Test Error 43.13\n",
      "Epoch   4 | Time    17 | Train Loss 0.5706 | Test Loss 2.892 | Test Error 41.20\n",
      "Epoch   5 | Time    17 | Train Loss 0.5375 | Test Loss 2.695 | Test Error 39.09\n",
      "Epoch   6 | Time    17 | Train Loss 0.4495 | Test Loss 2.246 | Test Error 34.17\n",
      "Epoch   7 | Time    17 | Train Loss 0.4884 | Test Loss 2.283 | Test Error 35.40\n",
      "Epoch   8 | Time    17 | Train Loss 0.4467 | Test Loss 2.466 | Test Error 34.55\n",
      "Epoch   9 | Time    17 | Train Loss 0.3741 | Test Loss 2.458 | Test Error 34.34\n",
      "Epoch  10 | Time    17 | Train Loss 0.4052 | Test Loss 2.296 | Test Error 34.22\n",
      "Epoch  11 | Time    17 | Train Loss 0.4131 | Test Loss 2.384 | Test Error 33.54\n",
      "Epoch  12 | Time    17 | Train Loss 0.4135 | Test Loss 2.323 | Test Error 31.44\n",
      "Epoch  13 | Time    17 | Train Loss 0.3905 | Test Loss 2.261 | Test Error 33.27\n",
      "Epoch  14 | Time    17 | Train Loss 0.3520 | Test Loss 1.969 | Test Error 31.05\n",
      "Epoch  15 | Time    17 | Train Loss 0.3951 | Test Loss 2.516 | Test Error 32.75\n",
      "Epoch  16 | Time    17 | Train Loss 0.2971 | Test Loss 2.223 | Test Error 30.17\n",
      "Epoch  17 | Time    18 | Train Loss 0.3461 | Test Loss 2.489 | Test Error 32.13\n",
      "Epoch  18 | Time    17 | Train Loss 0.2911 | Test Loss 2.470 | Test Error 33.23\n",
      "Epoch  19 | Time    17 | Train Loss 0.3097 | Test Loss 2.519 | Test Error 34.92\n",
      "Epoch  20 | Time    17 | Train Loss 0.3137 | Test Loss 2.516 | Test Error 34.15\n",
      "Epoch  21 | Time    18 | Train Loss 0.3219 | Test Loss 2.318 | Test Error 34.40\n",
      "Epoch  22 | Time    17 | Train Loss 0.3206 | Test Loss 2.390 | Test Error 30.78\n",
      "Epoch  23 | Time    18 | Train Loss 0.3369 | Test Loss 2.626 | Test Error 31.64\n",
      "Epoch  24 | Time    17 | Train Loss 0.3127 | Test Loss 2.178 | Test Error 29.49\n",
      "Epoch  25 | Time    17 | Train Loss 0.3004 | Test Loss 2.778 | Test Error 32.53\n",
      "Epoch  26 | Time    17 | Train Loss 0.3422 | Test Loss 2.180 | Test Error 31.67\n",
      "Epoch  27 | Time    17 | Train Loss 0.2825 | Test Loss 2.180 | Test Error 29.70\n",
      "Epoch  28 | Time    17 | Train Loss 0.2904 | Test Loss 2.116 | Test Error 29.35\n",
      "Epoch  29 | Time    17 | Train Loss 0.2694 | Test Loss 2.007 | Test Error 29.01\n",
      "Epoch  30 | Time    17 | Train Loss 0.2485 | Test Loss 2.031 | Test Error 28.71\n",
      "Epoch  31 | Time    17 | Train Loss 0.2750 | Test Loss 2.233 | Test Error 28.76\n",
      "Epoch  32 | Time    17 | Train Loss 0.2981 | Test Loss 2.238 | Test Error 29.31\n",
      "Epoch  33 | Time    17 | Train Loss 0.2877 | Test Loss 2.205 | Test Error 28.45\n",
      "Epoch  34 | Time    17 | Train Loss 0.2780 | Test Loss 2.318 | Test Error 30.24\n",
      "Epoch  35 | Time    17 | Train Loss 0.2515 | Test Loss 2.074 | Test Error 30.48\n",
      "Epoch  36 | Time    17 | Train Loss 0.2792 | Test Loss 2.140 | Test Error 28.69\n",
      "Epoch  37 | Time    17 | Train Loss 0.3109 | Test Loss 2.269 | Test Error 30.23\n",
      "Epoch  38 | Time    17 | Train Loss 0.2434 | Test Loss 2.225 | Test Error 27.37\n",
      "Epoch  39 | Time    17 | Train Loss 0.2471 | Test Loss 2.595 | Test Error 31.02\n",
      "Epoch  40 | Time    17 | Train Loss 0.2670 | Test Loss 2.104 | Test Error 27.15\n",
      "Epoch  41 | Time    17 | Train Loss 0.2430 | Test Loss 2.085 | Test Error 28.02\n",
      "Epoch  42 | Time    17 | Train Loss 0.2350 | Test Loss 2.099 | Test Error 27.44\n",
      "Epoch  43 | Time    17 | Train Loss 0.2265 | Test Loss 2.362 | Test Error 29.25\n",
      "Epoch  44 | Time    17 | Train Loss 0.2033 | Test Loss 2.158 | Test Error 26.66\n",
      "Epoch  45 | Time    17 | Train Loss 0.2714 | Test Loss 2.077 | Test Error 28.89\n",
      "Epoch  46 | Time    17 | Train Loss 0.2243 | Test Loss 2.182 | Test Error 26.90\n",
      "Epoch  47 | Time    17 | Train Loss 0.2654 | Test Loss 2.130 | Test Error 27.87\n",
      "Epoch  48 | Time    17 | Train Loss 0.2077 | Test Loss 2.440 | Test Error 26.56\n",
      "Epoch  49 | Time    17 | Train Loss 0.2410 | Test Loss 2.059 | Test Error 26.38\n",
      "Epoch  50 | Time    18 | Train Loss 0.1900 | Test Loss 2.125 | Test Error 27.08\n",
      "Epoch  51 | Time    17 | Train Loss 0.1950 | Test Loss 2.067 | Test Error 26.67\n",
      "Epoch  52 | Time    17 | Train Loss 0.2144 | Test Loss 2.146 | Test Error 27.11\n",
      "Epoch  53 | Time    17 | Train Loss 0.1880 | Test Loss 2.156 | Test Error 25.76\n",
      "Epoch  54 | Time    17 | Train Loss 0.1793 | Test Loss 2.413 | Test Error 26.83\n",
      "Epoch  55 | Time    17 | Train Loss 0.1733 | Test Loss 2.243 | Test Error 27.70\n",
      "Epoch  56 | Time    17 | Train Loss 0.1636 | Test Loss 2.223 | Test Error 26.58\n",
      "Epoch  57 | Time    17 | Train Loss 0.1577 | Test Loss 2.059 | Test Error 25.88\n",
      "Epoch  58 | Time    17 | Train Loss 0.1722 | Test Loss 2.013 | Test Error 25.94\n",
      "Epoch  59 | Time    17 | Train Loss 0.1494 | Test Loss 2.112 | Test Error 26.52\n",
      "Epoch  60 | Time    17 | Train Loss 0.1661 | Test Loss 2.239 | Test Error 26.64\n",
      "Epoch  61 | Time    18 | Train Loss 0.1663 | Test Loss 2.249 | Test Error 27.78\n",
      "Epoch  62 | Time    17 | Train Loss 0.1243 | Test Loss 2.278 | Test Error 26.12\n",
      "Epoch  63 | Time    18 | Train Loss 0.1197 | Test Loss 2.181 | Test Error 25.37\n",
      "Epoch  64 | Time    18 | Train Loss 0.1679 | Test Loss 2.280 | Test Error 26.74\n",
      "Epoch  65 | Time    17 | Train Loss 0.1678 | Test Loss 2.448 | Test Error 26.09\n",
      "Epoch  66 | Time    17 | Train Loss 0.1517 | Test Loss 1.995 | Test Error 25.00\n",
      "Epoch  67 | Time    17 | Train Loss 0.1385 | Test Loss 2.182 | Test Error 25.51\n",
      "Epoch  68 | Time    17 | Train Loss 0.1281 | Test Loss 2.095 | Test Error 24.88\n",
      "Epoch  69 | Time    17 | Train Loss 0.1152 | Test Loss 2.320 | Test Error 26.11\n",
      "Epoch  70 | Time    17 | Train Loss 0.1132 | Test Loss 2.179 | Test Error 24.86\n",
      "Epoch  71 | Time    17 | Train Loss 0.1155 | Test Loss 2.157 | Test Error 25.17\n",
      "Epoch  72 | Time    17 | Train Loss 0.0978 | Test Loss 2.183 | Test Error 24.62\n",
      "Epoch  73 | Time    17 | Train Loss 0.1001 | Test Loss 2.171 | Test Error 24.65\n",
      "Epoch  74 | Time    17 | Train Loss 0.0780 | Test Loss 2.359 | Test Error 24.75\n",
      "Epoch  75 | Time    17 | Train Loss 0.0876 | Test Loss 2.125 | Test Error 24.29\n",
      "Epoch  76 | Time    17 | Train Loss 0.0992 | Test Loss 2.274 | Test Error 24.71\n",
      "Epoch  77 | Time    17 | Train Loss 0.0674 | Test Loss 2.208 | Test Error 24.28\n",
      "Epoch  78 | Time    17 | Train Loss 0.0463 | Test Loss 2.265 | Test Error 24.07\n",
      "Epoch  79 | Time    17 | Train Loss 0.0646 | Test Loss 2.244 | Test Error 23.84\n",
      "Epoch  80 | Time    18 | Train Loss 0.0656 | Test Loss 2.278 | Test Error 23.95\n",
      "Epoch  81 | Time    17 | Train Loss 0.0413 | Test Loss 2.236 | Test Error 23.73\n",
      "Epoch  82 | Time    17 | Train Loss 0.0395 | Test Loss 2.209 | Test Error 23.82\n",
      "Epoch  83 | Time    17 | Train Loss 0.0429 | Test Loss 2.262 | Test Error 23.61\n",
      "Epoch  84 | Time    17 | Train Loss 0.0430 | Test Loss 2.303 | Test Error 23.56\n",
      "Epoch  85 | Time    17 | Train Loss 0.0266 | Test Loss 2.259 | Test Error 23.52\n",
      "Epoch  86 | Time    18 | Train Loss 0.0384 | Test Loss 2.358 | Test Error 23.60\n",
      "Epoch  87 | Time    18 | Train Loss 0.0195 | Test Loss 2.342 | Test Error 23.31\n",
      "Epoch  88 | Time    18 | Train Loss 0.0217 | Test Loss 2.334 | Test Error 23.29\n",
      "Epoch  89 | Time    17 | Train Loss 0.0223 | Test Loss 2.340 | Test Error 23.04\n",
      "Epoch  90 | Time    17 | Train Loss 0.0128 | Test Loss 2.386 | Test Error 23.19\n",
      "Epoch  91 | Time    17 | Train Loss 0.0128 | Test Loss 2.411 | Test Error 23.11\n",
      "Epoch  92 | Time    17 | Train Loss 0.0110 | Test Loss 2.393 | Test Error 23.11\n",
      "Epoch  93 | Time    17 | Train Loss 0.0122 | Test Loss 2.369 | Test Error 22.88\n",
      "Epoch  94 | Time    17 | Train Loss 0.0167 | Test Loss 2.401 | Test Error 22.97\n",
      "Epoch  95 | Time    17 | Train Loss 0.0137 | Test Loss 2.403 | Test Error 22.86\n",
      "Epoch  96 | Time    17 | Train Loss 0.0176 | Test Loss 2.400 | Test Error 22.97\n",
      "Epoch  97 | Time    17 | Train Loss 0.0088 | Test Loss 2.388 | Test Error 22.94\n",
      "Epoch  98 | Time    17 | Train Loss 0.0114 | Test Loss 2.401 | Test Error 22.93\n",
      "Epoch  99 | Time    17 | Train Loss 0.0123 | Test Loss 2.408 | Test Error 22.86\n",
      "Epoch 100 | Time    17 | Train Loss 0.0119 | Test Loss 2.396 | Test Error 22.96\n"
     ]
    }
   ],
   "source": [
    "# /////////////// Training ///////////////\n",
    "def train():\n",
    "    net.train()  # enter train mode\n",
    "    loss_avg = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # forward\n",
    "        x = net(data)\n",
    "\n",
    "        # backward\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(x, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "# test function\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward\n",
    "            output = net(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            # test loss average\n",
    "            loss_avg += float(loss.data)        \n",
    "    \n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Make save directory\n",
    "if not os.path.exists(args['save']):\n",
    "    os.makedirs(args['save'])\n",
    "if not os.path.isdir(args['save']):\n",
    "    raise Exception('%s is not a dir' % args['save'])\n",
    "\n",
    "with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_baseline_training_results.csv'), 'w') as f:\n",
    "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
    "\n",
    "print('Beginning Training\\n')\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(start_epoch, args['epochs']):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join('/home/yg534/OOD-detection-using-OECC/CIFAR/models/cam1_model' + '.pt'))\n",
    "\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                      '_baseline_training_results.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy']\n",
    "        ))\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1617946127516,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "mo1ayNY9Fvgv"
   },
   "outputs": [],
   "source": [
    "path = F\"/content/drive/MyDrive/distributed_learning/OOD-detection-using-OECC/CIFAR/baseline model/baseline_model.pt\"\n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5521,
     "status": "ok",
     "timestamp": 1617936294642,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "nq7-c7-shGa9",
    "outputId": "5b06afb2-4ec5-4dab-ab0e-29cfd8d4c9a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate 3.70\n",
      "\n",
      "Using CIFAR-10 as typical data\n",
      "\n",
      "\n",
      "CIFAR-100 Detection\n",
      "FPR95:\t\t\t57.38\n",
      "AUROC: \t\t\t87.75\n",
      "AUPR:  \t\t\t62.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean Test Results\n",
      "FPR95:\t\t\t57.38\n",
      "AUROC: \t\t\t87.75\n",
      "AUPR:  \t\t\t62.96\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "\n",
    "# /////////////// Detection Prelims ///////////////\n",
    "\n",
    "ood_num_examples = len(test_data) // 5\n",
    "expected_ap = ood_num_examples / (ood_num_examples + len(test_data))\n",
    "\n",
    "concat = lambda x: np.concatenate(x, axis=0)\n",
    "to_np = lambda x: x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_ood_scores(loader, in_dist=False):\n",
    "    _score = []\n",
    "    out_conf_score = []\n",
    "    in_conf_score = []\n",
    "    _right_score = []\n",
    "    _wrong_score = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            if batch_idx >= ood_num_examples // args[\n",
    "                    'test_bs'] and in_dist is False:\n",
    "                break\n",
    "\n",
    "#             data = data.cuda(device)\n",
    "            data = data.cuda()\n",
    "\n",
    "            output = net(data)\n",
    "            smax = to_np(F.softmax(output, dim=1))\n",
    "\n",
    "            if True:\n",
    "                _score.append(\n",
    "                    to_np((output.mean(1) - torch.logsumexp(output, dim=1))))\n",
    "                out_conf_score.append(np.max(smax, axis=1))\n",
    "            else:\n",
    "                _score.append(-np.max(smax, axis=1))\n",
    "                out_conf_score.append(np.max(smax, axis=1))\n",
    "\n",
    "            if in_dist:\n",
    "                in_conf_score.append(np.max(smax, axis=1))\n",
    "                preds = np.argmax(smax, axis=1)\n",
    "                targets = target.numpy().squeeze()\n",
    "                right_indices = preds == targets\n",
    "                wrong_indices = np.invert(right_indices)\n",
    "\n",
    "                if False:\n",
    "                    _right_score.append(\n",
    "                        to_np((output.mean(1) -\n",
    "                               torch.logsumexp(output, dim=1)))[right_indices])\n",
    "                    _wrong_score.append(\n",
    "                        to_np((output.mean(1) -\n",
    "                               torch.logsumexp(output, dim=1)))[wrong_indices])\n",
    "                else:\n",
    "                    _right_score.append(-np.max(smax[right_indices], axis=1))\n",
    "                    _wrong_score.append(-np.max(smax[wrong_indices], axis=1))\n",
    "\n",
    "    if in_dist:\n",
    "        return concat(in_conf_score).copy(), concat(_score).copy(), concat(_right_score).copy(), concat(_wrong_score).copy()\n",
    "    else:\n",
    "        return concat(out_conf_score).copy(), concat(_score)[:ood_num_examples].copy()\n",
    "\n",
    "\n",
    "in_conf_score, in_score, right_score, wrong_score = get_ood_scores(test_loader, in_dist=True)\n",
    "\n",
    "num_right = len(right_score)\n",
    "num_wrong = len(wrong_score)\n",
    "print('Error Rate {:.2f}'.format(100 * num_wrong / (num_wrong + num_right)))\n",
    "# f.write('\\nError Rate {:.2f}'.format(100 * num_wrong /\n",
    "#                                      (num_wrong + num_right)))\n",
    "\n",
    "# /////////////// End Detection Prelims ///////////////\n",
    "\n",
    "print('\\nUsing CIFAR-10 as typical data') if num_classes == 10 else print(\n",
    "    '\\nUsing CIFAR-100 as typical data')\n",
    "# f.write('\\nUsing CIFAR-10 as typical data') if num_classes == 10 else f.write(\n",
    "#     '\\nUsing CIFAR-100 as typical data')\n",
    "\n",
    "# /////////////// Error Detection ///////////////\n",
    "\n",
    "# print('\\n\\nError Detection')\n",
    "# f.write('\\n\\nError Detection')\n",
    "# show_performance(wrong_score, right_score, f, method_name=args['method_name'])\n",
    "\n",
    "# /////////////// OOD Detection ///////////////\n",
    "auroc_list, aupr_list, fpr_list = [], [], []\n",
    "\n",
    "\n",
    "def get_and_print_results(ood_loader, num_to_avg=1):\n",
    "\n",
    "    aurocs, auprs, fprs = [], [], []\n",
    "    for _ in range(num_to_avg):\n",
    "        out_conf_score, out_score = get_ood_scores(ood_loader)\n",
    "        measures = get_measures(out_score, in_score)\n",
    "        aurocs.append(measures[0])\n",
    "        auprs.append(measures[1])\n",
    "        fprs.append(measures[2])\n",
    "\n",
    "    auroc = np.mean(aurocs)\n",
    "    aupr = np.mean(auprs)\n",
    "    fpr = np.mean(fprs)\n",
    "    auroc_list.append(auroc)\n",
    "    aupr_list.append(aupr)\n",
    "    fpr_list.append(fpr)\n",
    "\n",
    "    if num_to_avg >= 5:\n",
    "        print_measures_with_std(aurocs, auprs, fprs, f, 'cifar10_wrn_OECC_tune')\n",
    "    else:\n",
    "        print_measures(auroc, aupr, fpr, f, 'cifar10_wrn_OECC_tune')\n",
    "    return out_conf_score    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# /////////////// CIFAR Data ///////////////\n",
    "\n",
    "\n",
    "ood_idx = get_target_label_idx(cifar_10_train.targets, [3, 4])\n",
    "ood_data = Subset(cifar_10_train, ood_idx)\n",
    "\n",
    "\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data,\n",
    "                                         batch_size=args['test_bs'],\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=args['prefetch'],\n",
    "                                         pin_memory=True)\n",
    "\n",
    "print(\n",
    "    '\\n\\nCIFAR-100 Detection') if True else print(\n",
    "        '\\n\\nCIFAR-10 Detection')\n",
    "# f.write('\\n\\nCIFAR-100 Detection'\n",
    "#         ) if 'cifar10_' in args['method_name'] else f.write(\n",
    "#             '\\n\\nCIFAR-10 Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "out_conf_score, out_score = get_ood_scores(ood_loader, in_dist=False)\n",
    "# /////////////// Mean Results ///////////////\n",
    "\n",
    "print('\\n\\nMean Test Results')\n",
    "# f.write('\\n\\nMean Test Results')\n",
    "print_measures(np.mean(auroc_list),\n",
    "               np.mean(aupr_list),\n",
    "               np.mean(fpr_list),\n",
    "               f,\n",
    "               method_name='cifar10_wrn_OECC_tune')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1617936023074,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "49I1PAy5uUBE",
    "outputId": "7b534670-10a4-41f2-a0af-23538e17bc76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99999666, -0.99549496, -0.9985436 , ..., -0.9997445 ,\n",
       "       -0.9999893 , -0.99996316], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1617936707070,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "gP2TeOzHuYFX",
    "outputId": "fec4d572-23bf-42ba-a4d6-5d8a996c7ed7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(in_score, density=True)\n",
    "\n",
    "ax.set_title(r'In Distribution')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1617936310999,
     "user": {
      "displayName": "Yuchong Geng",
      "photoUrl": "",
      "userId": "13573410025212938441"
     },
     "user_tz": 240
    },
    "id": "-59aFuyCySvg",
    "outputId": "54a9d0d8-ae60-4142-ea46-785f107a8b46"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(out_score, density=True)\n",
    "\n",
    "ax.set_title(r'Out of Distribution')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baseline_cifar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
