{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from CIFAR.models.wrn import WideResNet\n",
    "import utils.svhn_loader as svhn\n",
    "from utils.validation_dataset import validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:28:25.400259Z",
     "start_time": "2019-10-23T03:28:25.396089Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WWxU3iYD0X5O"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        'calibration': '',\n",
    "        'epochs': 100,\n",
    "        'dataset':'cifar10',\n",
    "        'learning_rate': 0.1,\n",
    "        'batch_size': 128,\n",
    "        'test_bs': 200,\n",
    "        'model':'wrn',\n",
    "        'momentum': 0.9,\n",
    "        'decay': 0.0005,\n",
    "        'save':'./results/baseline',\n",
    "        'load': '',\n",
    "        'test': 'store_true',\n",
    "        'layers':40,\n",
    "        'widen_factor':2,\n",
    "        'droprate':0.3,\n",
    "        'ngpu': 1,\n",
    "        'prefetch': 4,    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:28:28.181002Z",
     "start_time": "2019-10-23T03:28:26.424910Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8110,
     "status": "ok",
     "timestamp": 1562790604362,
     "user": {
      "displayName": "Aristotelis - Angelos Papadopoulos",
      "photoUrl": "https://lh6.googleusercontent.com/-irX6pXaWHWk/AAAAAAAAAAI/AAAAAAAAAB4/zcuYCe7Bl38/s64/photo.jpg",
      "userId": "12133508143730271082"
     },
     "user_tz": 420
    },
    "id": "iVaB5bl_JVri",
    "outputId": "cb269a50-6bc7-4b1c-f16e-20ac67c82309"
   },
   "outputs": [],
   "source": [
    "root='./'\n",
    "\n",
    "state = {k: v for k, v in args.items()}\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "train_transform = trn.Compose([trn.RandomHorizontalFlip(), trn.RandomCrop(32, padding=4),\n",
    "                               trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "\n",
    "if args['dataset'] == 'cifar10':\n",
    "    train_data = dset.CIFAR10(root, train=True, download=True, transform=train_transform)\n",
    "    test_data = dset.CIFAR10(root, train=False, download=True, transform=test_transform)\n",
    "    num_classes = 10\n",
    "else:\n",
    "    train_data = dset.CIFAR100(root, train=True, download=True, transform=train_transform)\n",
    "    test_data = dset.CIFAR100(root, train=False, download=True, transform=test_transform)\n",
    "    num_classes = 100\n",
    "\n",
    "calib_indicator = ''\n",
    "if args['calibration']:\n",
    "    train_data, val_data = validation_split(train_data, val_share=0.1)\n",
    "    calib_indicator = '_calib'\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=args['batch_size'], shuffle=True,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=args['test_bs'], shuffle=False,\n",
    "    num_workers=args['prefetch'], pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T03:28:28.258452Z",
     "start_time": "2019-10-23T03:28:28.183854Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "net = WideResNet(args['layers'], num_classes, args['widen_factor'], dropRate=args['droprate'])\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "# Restore model if desired\n",
    "if args['load'] != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        model_name = os.path.join( args['load'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_baseline_epoch_' + str(i) + '.pt')\n",
    "        if os.path.isfile(model_name):\n",
    "            net.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            start_epoch = i + 1\n",
    "            break\n",
    "    if start_epoch == 0:\n",
    "        assert False, \"could not resume\"\n",
    "\n",
    "net.cuda()\n",
    "torch.cuda.manual_seed(1)\n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "    weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "\n",
    "def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "            1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_annealing(\n",
    "        step,\n",
    "        args['epochs'] * len(train_loader),\n",
    "        1,  # since lr_lambda computes multiplicative factor\n",
    "        1e-6 / args['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T04:34:36.132388Z",
     "start_time": "2019-10-23T03:28:29.487850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7891974,
     "status": "ok",
     "timestamp": 1562798498989,
     "user": {
      "displayName": "Aristotelis - Angelos Papadopoulos",
      "photoUrl": "https://lh6.googleusercontent.com/-irX6pXaWHWk/AAAAAAAAAAI/AAAAAAAAAB4/zcuYCe7Bl38/s64/photo.jpg",
      "userId": "12133508143730271082"
     },
     "user_tz": 420
    },
    "id": "eQYV7aTgyGUQ",
    "outputId": "77afdf0e-24e8-4b7e-b810-371a343586a6"
   },
   "outputs": [],
   "source": [
    "# /////////////// Training ///////////////\n",
    "def train():\n",
    "    net.train()  # enter train mode\n",
    "    loss_avg = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # forward\n",
    "        x = net(data)\n",
    "\n",
    "        # backward\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(x, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "# test function\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward\n",
    "            output = net(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            # test loss average\n",
    "            loss_avg += float(loss.data)        \n",
    "    \n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# Make save directory\n",
    "if not os.path.exists(args['save']):\n",
    "    os.makedirs(args['save'])\n",
    "if not os.path.isdir(args['save']):\n",
    "    raise Exception('%s is not a dir' % args['save'])\n",
    "\n",
    "with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_baseline_training_results.csv'), 'w') as f:\n",
    "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
    "\n",
    "print('Beginning Training\\n')\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(start_epoch, args['epochs']):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                            '_baseline_epoch_' + str(epoch) + '.pt'))\n",
    "    # Let us not waste space and delete the previous model\n",
    "    prev_path = os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                             '_baseline_epoch_' + str(epoch - 1) + '.pt')\n",
    "    if os.path.exists(prev_path): os.remove(prev_path)\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                      '_baseline_training_results.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy']\n",
    "        ))\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "oe_baseline_cifar.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
