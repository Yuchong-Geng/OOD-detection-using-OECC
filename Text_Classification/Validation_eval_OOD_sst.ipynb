{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T01:29:45.271984Z",
     "start_time": "2019-11-04T01:29:44.186222Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UtIKnY967rmO"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import math\n",
    "import time\n",
    "from bisect import bisect_left\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable as V\n",
    "import torchtext\n",
    "\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from utils.display_results import get_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T01:29:46.588143Z",
     "start_time": "2019-11-04T01:29:46.560858Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_yvOqAe8ElRF"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    batch_size = 64,\n",
    "    in_dist_dataset = 'sst',\n",
    "    method='OECC',\n",
    "    save = 'results',\n",
    "    load = 'results', \n",
    "    oe_dataset = 'wikitext2'\n",
    "    )\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "cudnn.benchmark = True  # fire on all cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T01:29:55.468513Z",
     "start_time": "2019-11-04T01:29:53.803050Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5169,
     "status": "ok",
     "timestamp": 1564467797273,
     "user": {
      "displayName": "Aristotelis - Angelos Papadopoulos",
      "photoUrl": "https://lh6.googleusercontent.com/-irX6pXaWHWk/AAAAAAAAAAI/AAAAAAAAAB4/zcuYCe7Bl38/s64/photo.jpg",
      "userId": "12133508143730271082"
     },
     "user_tz": 420
    },
    "id": "QgpuEZwtzMV4",
    "outputId": "cec99551-d715-4017-8d4b-9c5a522d7ed4"
   },
   "outputs": [],
   "source": [
    "# ============================ SST ============================ #\n",
    "# set up fields\n",
    "TEXT_sst = data.Field(pad_first=True)\n",
    "LABEL_sst = data.Field(sequential=False)\n",
    "\n",
    "# make splits for data\n",
    "train_sst, val_sst, test_sst = datasets.SST.splits(\n",
    "    TEXT_sst, LABEL_sst, fine_grained=False, train_subtrees=False,\n",
    "    filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "# build vocab\n",
    "TEXT_sst.build_vocab(train_sst, max_size=10000)\n",
    "LABEL_sst.build_vocab(train_sst, max_size=10000)\n",
    "print('vocab length for SST(including special tokens):', len(TEXT_sst.vocab))\n",
    "num_classes = len(LABEL_sst.vocab)\n",
    "print('num labels:', len(LABEL_sst.vocab))\n",
    "# create our own iterator, avoiding the calls to build_vocab in SST.iters\n",
    "train_iter_sst, val_iter_sst, test_iter_sst = data.BucketIterator.splits(\n",
    "    (train_sst, val_sst, test_sst), batch_size=args.batch_size, repeat=False)\n",
    "\n",
    "\n",
    "ood_num_examples = len(test_iter_sst.dataset) // 5\n",
    "expected_ap = ood_num_examples / (ood_num_examples + len(test_iter_sst.dataset))\n",
    "recall_level = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T01:30:04.058341Z",
     "start_time": "2019-11-04T01:29:59.515662Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 996928,
     "status": "ok",
     "timestamp": 1564468811248,
     "user": {
      "displayName": "Aristotelis - Angelos Papadopoulos",
      "photoUrl": "https://lh6.googleusercontent.com/-irX6pXaWHWk/AAAAAAAAAAI/AAAAAAAAAB4/zcuYCe7Bl38/s64/photo.jpg",
      "userId": "12133508143730271082"
     },
     "user_tz": 420
    },
    "id": "OLL-xqubzVFF",
    "outputId": "35b5b924-5ea3-42a4-91ce-5e3883f6419b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ClfGRU(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(len(TEXT_sst.vocab), 50, padding_idx=1)\n",
    "        self.gru = nn.GRU(input_size=50, hidden_size=128, num_layers=2, bias=True, batch_first=True, bidirectional=False)\n",
    "        self.linear = nn.Linear(128, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        hidden = self.gru(embeds)[1][1]  # select h_n, and select the 2nd layer\n",
    "        logits = self.linear(hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "model = ClfGRU(num_classes-1)\n",
    "model.load_state_dict(torch.load(f'./{args.load}/{args.in_dist_dataset}/{args.method}/{args.oe_dataset}/model_finetune.dict'))  # change location as per our method\n",
    "print('\\nLoaded model.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 20 Newsgroup and TREC as validation OOD data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T01:30:11.603232Z",
     "start_time": "2019-11-04T01:30:09.492734Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================ 20 Newsgroups ============================ #\n",
    "TEXT_20ng = data.Field(pad_first=True, lower=True, fix_length=100)\n",
    "LABEL_20ng = data.Field(sequential=False)\n",
    "\n",
    "train_20ng = data.TabularDataset(path='20_newsgroup_train.csv',\n",
    "                                 format='csv',\n",
    "                                 fields=[('text', TEXT_20ng), ('label', LABEL_20ng)])\n",
    "\n",
    "test_20ng = data.TabularDataset(path='20_newsgroup_test.csv',\n",
    "                                 format='csv',\n",
    "                                 fields=[('text', TEXT_20ng), ('label', LABEL_20ng)])\n",
    "\n",
    "TEXT_20ng.build_vocab(train_20ng, max_size=10000)\n",
    "LABEL_20ng.build_vocab(train_20ng, max_size=10000)\n",
    "print('vocab length (including special tokens):', len(TEXT_20ng.vocab))\n",
    "#num_classes = len(LABEL_20ng.vocab)\n",
    "print('num labels:', len(LABEL_20ng.vocab))\n",
    "train_iter_20ng = data.BucketIterator(train_20ng, batch_size=args.batch_size, repeat=False)\n",
    "test_iter_20ng = data.BucketIterator(test_20ng, batch_size=args.batch_size, repeat=False)\n",
    "\n",
    "\n",
    "# ============================ TREC ============================ #\n",
    "# set up fields\n",
    "TEXT_trec = data.Field(pad_first=True, lower=True)\n",
    "LABEL_trec = data.Field(sequential=False)\n",
    "\n",
    "# make splits for data\n",
    "train_trec, test_trec = datasets.TREC.splits(TEXT_trec, LABEL_trec, fine_grained=True)\n",
    "\n",
    "\n",
    "# build vocab\n",
    "TEXT_trec.build_vocab(train_trec, max_size=10000)\n",
    "LABEL_trec.build_vocab(train_trec, max_size=10000)\n",
    "print('vocab length (including special tokens):', len(TEXT_trec.vocab))\n",
    "#num_classes = len(LABEL_trec.vocab)\n",
    "print('num labels:', len(LABEL_trec.vocab))\n",
    "\n",
    "# make iterators\n",
    "train_iter_trec, test_iter_trec = data.BucketIterator.splits(\n",
    "    (train_trec, test_trec), batch_size=args.batch_size, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T01:31:34.981137Z",
     "start_time": "2019-11-04T01:31:30.846701Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1015250,
     "status": "ok",
     "timestamp": 1564468829981,
     "user": {
      "displayName": "Aristotelis - Angelos Papadopoulos",
      "photoUrl": "https://lh6.googleusercontent.com/-irX6pXaWHWk/AAAAAAAAAAI/AAAAAAAAAB4/zcuYCe7Bl38/s64/photo.jpg",
      "userId": "12133508143730271082"
     },
     "user_tz": 420
    },
    "id": "41b-WxEkAq6N",
    "outputId": "b9ad4857-92e9-43ce-9ec1-5a71f313b7ef"
   },
   "outputs": [],
   "source": [
    "def get_scores(dataset_iterator, ood=False, translation_dataset = False, snli=False):\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    \n",
    "    outlier_scores = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(iter(dataset_iterator)):\n",
    "        if ood and (batch_idx * args.batch_size > ood_num_examples):\n",
    "            break\n",
    "\n",
    "        if snli:\n",
    "            inputs = batch.hypothesis.t()\n",
    "        else:\n",
    "            if translation_dataset:\n",
    "                inputs = batch.src.t()\n",
    "            else:        \n",
    "                inputs = batch.text.t()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        \n",
    "        smax = F.softmax(logits - torch.max(logits, dim=1, keepdim=True)[0], dim=1)\n",
    "        msp = -1 * torch.max(smax, dim=1)[0]\n",
    "      \n",
    "    #      ce_to_unif = F.log_softmax(logits - torch.max(logits, dim=1, keepdim=True)[0], dim=1).mean(1)  # negative cross entropy\n",
    "        # test = (F.softmax(logits - torch.max(logits, dim=1, keepdim=True)[0], dim=1) * (1 / torch.FloatTensor([logits.size(1)]).cuda().mean()).log()).sum(1)\n",
    "#         test = -1 * (F.log_softmax(logits - torch.max(logits, dim=1, keepdim=True)[0], dim=1) * smax).sum(1)\n",
    "\n",
    "        outlier_scores.extend(list(msp.data.numpy()))\n",
    "\n",
    "    return outlier_scores\n",
    "\n",
    "\n",
    "\n",
    "# ============================ OECC ============================ #\n",
    "\n",
    "test_scores = get_scores(test_iter_sst)\n",
    "\n",
    "titles = ['20 Newsgroup', 'TREC']\n",
    "\n",
    "iterators = [train_iter_20ng, train_iter_trec]\n",
    "\n",
    "\n",
    "mean_fprs = []\n",
    "mean_aurocs = []\n",
    "mean_auprs = []\n",
    "\n",
    "f = open(f'./{args.save}/{args.in_dist_dataset}/{args.method}/{args.oe_dataset}/OECC_eval_results.txt', 'w')\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    title = titles[i]\n",
    "    iterator = iterators[i]\n",
    "    \n",
    "    if '30K' in title or '16' in title:\n",
    "        translation_dataset=True\n",
    "    else:\n",
    "        translation_dataset=False\n",
    "        \n",
    "    print(f'\\n{title}')\n",
    "    f.write(f'\\n{title}')\n",
    "    fprs, aurocs, auprs = [], [], []\n",
    "    for i in range(10):\n",
    "        ood_scores = get_scores(iterator, ood=True, translation_dataset = translation_dataset, snli=True) if 'SNLI' in title else get_scores(iterator, ood=True, translation_dataset=translation_dataset)\n",
    "        fpr, auroc, aupr = get_performance(ood_scores, test_scores, expected_ap, recall_level=recall_level)\n",
    "        fprs.append(fpr)\n",
    "        aurocs.append(auroc)\n",
    "        auprs.append(aupr)\n",
    "\n",
    "    print(f'FPR{int(100 * recall_level):d}:\\t\\t\\t{np.mean(fprs):.4f} ({np.std(fprs):.4f})')\n",
    "    f.write(f'\\nFPR{int(100 * recall_level):d}:\\t\\t\\t{np.mean(fprs):.4f} ({np.std(fprs):.4f})')\n",
    "    print(f'AUROC:\\t\\t\\t{np.mean(aurocs):.4f} ({np.std(aurocs):.4f})')\n",
    "    f.write(f'\\nAUROC:\\t\\t\\t{np.mean(aurocs):.4f} ({np.std(aurocs):.4f})')\n",
    "    print(f'AUPR:\\t\\t\\t{np.mean(auprs):.4f} ({np.std(auprs):.4f})')\n",
    "    f.write(f'\\nAUPR:\\t\\t\\t{np.mean(auprs):.4f} ({np.std(auprs):.4f})\\n')\n",
    "\n",
    "    mean_fprs.append(np.mean(fprs))\n",
    "    mean_aurocs.append(np.mean(aurocs))\n",
    "    mean_auprs.append(np.mean(auprs))\n",
    "\n",
    "print()\n",
    "print(f'OOD dataset mean FPR: {np.mean(mean_fprs):.4f}')\n",
    "f.write(f'\\nOOD dataset mean FPR: {np.mean(mean_fprs):.4f}')\n",
    "print(f'OOD dataset mean AUROC: {np.mean(mean_aurocs):.4f}')\n",
    "f.write(f'\\nOOD dataset mean AUROC: {np.mean(mean_aurocs):.4f}')\n",
    "print(f'OOD dataset mean AUPR: {np.mean(mean_auprs):.4f}')\n",
    "f.write(f'\\nOOD dataset mean AUPR: {np.mean(mean_auprs):.4f}')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4s0ES4Qaujc4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eval_OOD_sst.ipynb",
   "provenance": [
    {
     "file_id": "1s7IYTjdG40I2GEObKfl4AFgLxncH4zJn",
     "timestamp": 1563772067136
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
