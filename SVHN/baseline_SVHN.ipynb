{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXDXpzKWMHGZ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from SVHN.models.allconv import AllConvNet\n",
    "from SVHN.models.wrn import WideResNet\n",
    "import utils.svhn_loader as svhn\n",
    "from utils.validation_dataset import validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Lmwhd8cMJrg"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        'calibration': '',\n",
    "        'epochs': 20,\n",
    "        'dataset':'svhn', \n",
    "        'learning_rate': 0.01,\n",
    "        'batch_size': 128,\n",
    "        'test_bs': 200,\n",
    "        'model':'wrn', \n",
    "        'momentum': 0.9,\n",
    "        'decay': 0.0005,\n",
    "        'save':'./SVHN/results/baseline',  \n",
    "        'load': '',\n",
    "        'test': 'store_true',\n",
    "        'layers':16,\n",
    "        'widen_factor':4,\n",
    "        'droprate':0.4,\n",
    "        'ngpu': 1,\n",
    "        'prefetch': 4,    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUO4Y4w4yUCa"
   },
   "outputs": [],
   "source": [
    "# !wget http://ufldl.stanford.edu/housenumbers/extra 32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzPtBqvIbSKK"
   },
   "outputs": [],
   "source": [
    "root='../SVHN' \n",
    "\n",
    "state = {k: v for k, v in args.items()}\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "train_data = svhn.SVHN(root, split='train_and_extra',\n",
    "                       transform=trn.ToTensor(), download=False)\n",
    "test_data = svhn.SVHN(root, split='test',\n",
    "                      transform=trn.ToTensor(), download=False)\n",
    "num_classes = 10\n",
    "\n",
    "calib_indicator = ''\n",
    "if args['calibration']:\n",
    "    train_data, val_data = validation_split(train_data, val_share=5000/604388.)\n",
    "    calib_indicator = 'calib_' \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=args['batch_size'], shuffle=True,\n",
    "    num_workers=args['prefetch'], pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=args['test_bs'], shuffle=False,\n",
    "    num_workers=args['prefetch'], pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3129397,
     "status": "ok",
     "timestamp": 1563857070804,
     "user": {
      "displayName": "Jiamian Wang",
      "photoUrl": "",
      "userId": "08424312081130452473"
     },
     "user_tz": -480
    },
    "id": "-nmXi9BFbZGY",
    "outputId": "d20b8669-a345-4d71-b228-29e67d35ec73"
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "if args['model'] == 'allconv':\n",
    "    net = AllConvNet(num_classes)\n",
    "else:\n",
    "    net = WideResNet(args['layers'], num_classes, args['widen_factor'], dropRate=args['droprate'])\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "# Restore model if desired\n",
    "if args['load'] != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        model_name = os.path.join( args['load'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_baseline_epoch_' + str(i) + '.pt')\n",
    "        if os.path.isfile(model_name):\n",
    "            net.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            start_epoch = i + 1\n",
    "            break\n",
    "    if start_epoch == 0:\n",
    "        assert False, \"could not resume\"\n",
    "\n",
    "if args['ngpu'] > 1:\n",
    "    net = torch.nn.DataParallel(net, device_ids=list(range(args['ngpu'])))\n",
    "\n",
    "if args['ngpu'] > 0:\n",
    "    net.cuda()\n",
    "    torch.cuda.manual_seed(1)\n",
    "\n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), state['learning_rate'], momentum=state['momentum'],\n",
    "    weight_decay=state['decay'], nesterov=True)\n",
    "\n",
    "\n",
    "def cosine_annealing(step, total_steps, lr_max, lr_min):\n",
    "    return lr_min + (lr_max - lr_min) * 0.5 * (\n",
    "            1 + np.cos(step / total_steps * np.pi))\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_annealing(\n",
    "        step,\n",
    "        args['epochs'] * len(train_loader),\n",
    "        1,  # since lr_lambda computes multiplicative factor\n",
    "        1e-6 / args['learning_rate']))\n",
    "\n",
    "\n",
    "# /////////////// Training ///////////////\n",
    "\n",
    "def train():\n",
    "    net.train()  # enter train mode\n",
    "    loss_avg = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.cuda(), target.long().cuda()  \n",
    "\n",
    "        # forward\n",
    "        x = net(data)\n",
    "\n",
    "        # backward\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(x, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # exponential moving average\n",
    "        loss_avg = loss_avg * 0.8 + float(loss) * 0.2\n",
    "\n",
    "    state['train_loss'] = loss_avg\n",
    "\n",
    "# test function\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.long().cuda()\n",
    "\n",
    "            # forward\n",
    "            output = net(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.eq(target.data).sum().item()\n",
    "\n",
    "            # test loss average\n",
    "            loss_avg += float(loss.data)\n",
    "\n",
    "    state['test_loss'] = loss_avg / len(test_loader)\n",
    "    state['test_accuracy'] = correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "# if args['test']:\n",
    "#     test()\n",
    "#     print(state)\n",
    "#     exit()\n",
    "\n",
    "# Make save directory\n",
    "if not os.path.exists(args['save']):\n",
    "    os.makedirs(args['save'])\n",
    "if not os.path.isdir(args['save']):\n",
    "    raise Exception('%s is not a dir' % args['save'])\n",
    "\n",
    "with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                                  '_baseline_training_results.csv'), 'w') as f:\n",
    "    f.write('epoch,time(s),train_loss,test_loss,test_error(%)\\n')\n",
    "\n",
    "print('Beginning Training\\n')\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(start_epoch, args['epochs']):\n",
    "    state['epoch'] = epoch\n",
    "\n",
    "    begin_epoch = time.time()\n",
    "\n",
    "    train()\n",
    "    test()\n",
    "\n",
    "    # Save model\n",
    "    torch.save(net.state_dict(),\n",
    "               os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                            '_baseline_epoch_' + str(epoch) + '.pt'))\n",
    "    # Let us not waste space and delete the previous model\n",
    "    prev_path = os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] +\n",
    "                             '_baseline_epoch_' + str(epoch - 1) + '.pt')\n",
    "    if os.path.exists(prev_path): os.remove(prev_path)\n",
    "\n",
    "    # Show results\n",
    "\n",
    "    with open(os.path.join(args['save'], args['dataset'] + calib_indicator + '_' + args['model'] + \n",
    "                                      '_baseline_training_results_epoch_20.csv'), 'a') as f:\n",
    "        f.write('%03d,%05d,%0.6f,%0.5f,%0.2f\\n' % (\n",
    "            (epoch + 1),\n",
    "            time.time() - begin_epoch,\n",
    "            state['train_loss'],\n",
    "            state['test_loss'],\n",
    "            100 - 100. * state['test_accuracy'],\n",
    "        ))\n",
    "\n",
    "    # # print state with rounded decimals\n",
    "    # print({k: round(v, 4) if isinstance(v, float) else v for k, v in state.items()})\n",
    "\n",
    "    print('Epoch {0:3d} | Time {1:5d} | Train Loss {2:.4f} | Test Loss {3:.3f} | Test Error {4:.2f}'.format(\n",
    "        (epoch + 1),\n",
    "        int(time.time() - begin_epoch),\n",
    "        state['train_loss'],\n",
    "        state['test_loss'],\n",
    "        100 - 100. * state['test_accuracy'])\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "oe_baseline_SVHN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
